---
title: "IA nelle Fondazioni Bancarie"
subtitle: "(Resoconto del corso ACRI)"
author: "**Luisa M. Mimmi**<br>(con estratti della presentazione di) **Fabio Fraticelli**"
date: today
date-format: "DD MMMM YYYY"
metadata-files:
  - brand/CRP-revealjs-theme.yml
format: revealjs
  # revealjs:
  #   output-file: presentazione.pdf
  #   pdf-separate-fragments: false
execute:
  echo: true
  include: true
  freeze: auto
---


## Programma del corso tenuto il 6/7 Novembre 2025

**L'IA al servizio delle Fondazioni di origine bancaria**

::: {style="font-size: 70%;"}
+ **Giorno 1 (9:30 ‚Äì 17:30)**
	+ Introduzione all‚ÄôIA
	+ IA per analisi del contesto
	+ IA per elaborazione di un bando
	+ IA per la valutazione dei progetti
+ **Giorno 2 (9:00 ‚Äì 13:00)**
	+ IA per Monitoraggio / Valutazione Impatto
	+ Governance e strategie di adozione
	+ Wrap-Up
:::


::: {.notes}
Speaker notes go here.
:::

## [INS] Docente {.notitle}

![](bib/pagine/png/fabio.png){.r-stretch}

 

## A che punto siamo con l'IA?


Tra ottimismo e scetticismo...


<!-- insert to pics side by side -->


![](assets/innov_cycle.png){width="65%"}


## A che punto siamo con l'IA (nelle Fondazioni Bancarie)?

<!-- insert to pics side by side -->
::: {.columns}
::: {.column width="50%"}
![Coffee break in ACRI](assets/caffe.jpg){width="65%"}
:::
::: {.column width="50%"}
![Adozione di IA tra i presenti](assets/sondaggio.jpg){width="65%"}
:::
:::	





# Cosa √® l'Intelligenza Artificiale (IA)?

## [INS] Un lavoro di oltre 70 anni {.notitle}

![](bib/pagine/png/unastoria.png){.r-stretch}

::: {.notes}
xxxxx
:::


## La Gen AI √® solo una parte

<!-- https://k21academy.com/ai-ml/what-is-generative-ai/ -->

::: {columns}

::: {.column width="40%"}

::: {style="font-size: 60%;"}
::: {.fragment}
**AI**: Insieme di tecniche che svolgono compiti tipici dell'intelligenza umana
<!-- (ragionamento, apprendimento, comprensione del linguaggio naturale, ecc.) -->
:::

::: {.fragment}
**ML**: Modelli allenati su dati senza istruzioni esplicite ‚Äî riconoscono pattern, fanno previsioni
<!-- viene meno la distinzione tra programmazione tradizionale e apprendimento automatico -->
:::

::: {.fragment}
**DL**: Reti neurali profonde con strati multipli che estraggono caratteristiche complesse dai dati
<!-- Questo strati successivi che estraggono caratteristiche e un algoritmo che aggiusta i pesi con backpropagation + gradient descent ‚Äî √® la base di tutta l‚ÄôIA neurale moderna, sia:  DISCRIMINATIVA CHE GENERATIVA (se aggiungi un livello di decodifica che produce ...) -->
:::

::: {.fragment}
**GenAI**: Invece che output predefiniti, creano nuovi contenuti (testo, immagini, audio) simili ai dati di addestramento
<!-- ‚ÄúAll‚Äôaumentare della complessit√† ‚Äî dal machine learning tradizionale al deep learning, fino alla generative AI ‚Äî crescono anche i costi: servono molti pi√π dati, modelli molto pi√π grandi e una capacit√† di calcolo enormemente superiore per addestrarli e mantenerli operativi.‚Äù -->
:::
:::
:::

::: {.column width="55%"}
![](assets/AI_bubbles.png)
:::

:::

::: {.notes}
- **Computer programming** : The programmer knows what the input and output looks like and write code to transform input into output _FUNCTION_ that _processes_ an input and _produces_ an output
	
- **Machine learning** : The programmer (instead of coding the function) MAY provide 	_EXAMPLES_ of input-output pairs to a learning algorithm that _learns_ a model that 	_approximates_ the transformation from input to output (a.k.a. "training the model") --  hence the importance of exposure to experience / data
	
	+ _SUPERVISED learning_ : we provide input and output pairs!!! (a.k.a. the right 	answers), then the MODEL can represent (model) the relationship between input and 	output adjusting a set of numbers (called PARAMETERS: weight, bias....) to minimize 	the error in predicting the output from the input
	+ _UNSUPERVISED learning_ : seeks to examine a collection of unlabeled examples and 	group them
	by some notion of shared commonality.

- **Deep learning**: Deep learning models are ML models that organize parameters into hierarchical layers. Features (INPUTs) are multiplied and added together repeatedly, with the OUTPUT from one layer of parameters being fed into the next layer ‚Äì before a prediction can be made.
	+ Il deep learning consente l‚Äôingegnerizzazione automatica delle caratteristiche e raggiunge un‚Äôaccuratezza superiore quando lavora con grandi set di dati.

> In pratica, il DL procede con strati successivi di analisi dei dati (pixel, parole, ecc.), producendo, dopo ogni strato, una rappresentazione intermedia dei dati es. da pixel ‚Üí bordi ‚Üí forme ‚Üí oggetti ‚Üí concetti). Ciascuno strato √® costituito da un insieme di **neuroni** artificiali, (nodi, i.e. mini modelli predittivi). Ogni strato elabora i dati in ingresso (combinazioni lineari pesate) e produce un **output** intermedio, che viene poi passato come input allo strato successivo ("deep" x i tanti livelli). In conclusione, l'ultimo strato fornisce l'**output**: un riconoscimento facciale, una diagnosi di patologia, una risposta del call center, la selezione di un candidato HR, l'identificazione di una transazione sospetta, ecc.

:::

## La rivoluzione: Deep Neural Networks


<!-- ![](assets/Neuron.png){.absolute left=0 width="30%"} -->
 
 
:::: {style="font-size: 45%;"} 
Ogni `strato` analizza dati in ingresso (e.g. pixel, parole) tramite un insieme di `neuroni` (i.e. mini modelli predittivi) -> produce un **output intermedio** -> che fa da **input** dello strato successivo. L'algoritmo confronta l'**output finale** con esempi noti e "aggiusta" i pesi dei neuroni per minimizzare l'errore. 
<!-- Forward propagation (andata e previsione)
Backpropagation l‚Äôerrore finale viene fatto retrocedere strato per strato, e in ciascuno strato vengono aggiornati tutti i pesi dei neuroni.  ottimizzato con `gradient descent`. -->
<!-- + `deep learning`, si riferisce al N. di strati -->

+ Esempio: `pixel ‚Üí bordi ‚Üí forme complesse ‚Üí oggetti ‚Üí personaggio`
+ Esempio: `token ‚Üí peso emotivo ‚Üí relazione tra parole ‚Üí Sentimento Positiva/Negativa`
::::


![](assets/DeepLearning.jpg){.absolute width="80%"}
 

<!-- ## [INS] Reti neurali alla base di `Generative AI` {.notitle} -->

<!-- ![](bib/pagine/png/allabase.png){.r-stretch} -->

::: {.notes}
DAtapizza : ret neurali https://www.youtube.com/watch?v=H8r8aGFBnXk
:::

## Il FT spiega `Generative LLM`

![_Financial Times_: `La storia dei Large Language Models (LLM)` <br>   [https://ig.ft.com/generative-ai/](https://ig.ft.com/generative-ai/)](assets/ft_generative.png) 

<!-- <br><br> -->

<!-- ::: aside -->
<!-- Dal _Financial Times_: `La storia dei Large Language Models (LLM)`, i.e. Deep Learning applicato al linguaggio naturale [https://ig.ft.com/generative-ai/](https://ig.ft.com/generative-ai/) -->

<!-- ::: -->

::: {.notes}
Gli LLM sono Deep Learning applicato al linguaggio.
- Gli LLM usano principalmente **Transformer** (un tipo particolare di rete neurale) invece dei fully connected layers classici
	- Input: parole/token (frammenti di testo)
	- Strati intermedi: estraggono significati, relazioni grammaticali, concetti
	- Output: previsione della prossima parola o risposta completa

+ **Transformers (come GPT)**: predicono il prossimo token in una sequenza, generando testo token per token

+ Transformers generano **embeddings**: rappresentazioni numeriche di parole/frasi che catturano il loro significato e contesto, permettendo al modello di "comprendere" relazioni semantiche.
:::



## Dal `ML` ad `Agentic AI` (‚úâÔ∏è)

```{r}
#| label: ai_taxonomy_1
#| echo: false
#| output: true

library(tibble)
library(flextable)

# Schema ML ‚Üí Generative ‚Üí AI ‚Üí Agent
ai_taxonomy_1 <- tribble(
  ~tipo                                                                                                        , ~esempio_richiesta               , ~tipo_algoritmo , ~esempio_email , ~esempio_brand ,

  "ML (classico)"                                                                                              , "Questa email √® spam?"          ,
  "Classificazione, Predizione, Riconoscimento"                                                                , #
  "Email ‚Üí classificata come SPAM o NON-SPAM (etichetta)"                                                    , "Outlook junk mail"              ,

  "Generative AI"                                                                                              , "Rispondi a questa email"        ,
  "Creazione, Generazione nuovi dati"                                                                          , #
  "Email ‚Üí genera bozza di risposta appropriata (tu la invii)"                                               , "ChatGPT"                        ,

  "AI (orchestrator)"                                                                                          , "Gestisci questa richiesta"      ,
  "Orchestrazione multi-strumento"                                                                             , #
  "Email ‚Üí capisce richiesta, cerca dati necessari nel DB, genera report con allegati (tu rivedi e invii)"   , "ChatGPT Plus (plugins)"         ,

  "Agent"                                                                                                      , "Occupati delle email arretrate" ,
  "Pianificazione ed esecuzione multi-step"                                                                    , #
  "Email ‚Üí legge, cerca dati, genera report, allega file, INVIA risposta (persegue obiettivi in autonomia!)" , "AutoGPT"
)

# Visualizza
# ai_taxonomy

# Oppure con formattazione migliore
ai_taxonomy_1 %>%
  flextable() %>%
  fontsize(size = 20, part = "header") %>% # Header pi√π grande
  fontsize(size = 16, part = "body") %>% # Body della tabella
  bold(part = "header") %>% # Grassetto per l'header
  # Change format of the second & fourth column es_richiesta italics
  flextable::italic(i = NULL, j = c(2, 4), part = "body") %>%
  flextable::color(i = NULL, j = c(2, 4), color = "#9f4136", part = "body") %>%
  # Change background of 1st column to light red
  flextable::bg(i = NULL, j = 1, bg = "#f18b83", part = "body") %>%
  flextable::bold(i = NULL, j = c(1, 3), part = "body") %>%
  # # Aggiungi footnote alla prima colonna (categoria)
  # footnote(
  # 	i = 1, j = 1,
  # 	value = as_paragraph("In senso lato tutti questi modelli sono AI"),
  # 	ref_symbols = "*",
  # 	part = "header") %>%
  # Cambia il testo nei header
  flextable::set_header_labels(
    tipo = "Categoria",
    esempio_richiesta = "Esempio di richiesta",
    tipo_algoritmo = "Tipo di algoritmo",
    esempio_email = "Esempio di output",
    esempio_brand = "Esempio di piattaforma"
  ) %>%
  autofit()

```


::: aside
[In senso lato, sono tutti modelli di **AI**]
:::


::: {.notes}

Perch√© gli agenti sono effettivamente pericolosi:

1. Azioni irreversibili nel mondo reale
	- cancellare database, inviare email a migliaia di persone, fare transazioni finanziarie.
2. Cascate di errori amplificati
	- la query restituisce TUTTI i pazienti, non solo quelli dovuti e fa spam di email
3. Allucinazioni con conseguenze reali
	- inventa dati, numeri di telefono, indirizzi email, ecc.
4. Disallineamento degli obiettivi
	- l'agente interpreta male l'obiettivo e agisce in modi indesiderati
5.  Mancanza di giudizio etico/contestuale
	- non capisce le sfumature sociali, culturali o etiche
	
Come mitigare i rischi:
- Supervisione umana costante ("_human-in-the-loop_")
- Limitare le azioni possibili dell'agente ("_whitelisting_ azioni permesse")
- Validazione e verifica dei risultati ("_checkpoints_ di sicurezza")

:::


## Dal `ML` ad `Agentic AI` (ü§ñ)

```{r}
#| label: ai_taxonomy
#| echo: false
#| output: true

library(tibble)
library(flextable)

# Schema ML ‚Üí Generative ‚Üí AI ‚Üí Agent
ai_taxonomy <- tribble(
  ~tipo                                                                   , ~es_richiesta                       , ~tipo_algoritmo , ~es_algoritmo , ~es_brand ,

  "ML (classico)"                                                         , "Dimmi cos'√® questo"               ,
  "Classificazione, Predizione, Riconoscimento"                           , #
  "Regressione Logistica, Random Forest, Reti Neurali, XGBoost, SVM"      ,
  "Excel (previsioni), Outlook junk mail, Google Photos (riconoscimento)" , # , scikit-learn, tidymodels, caret

  "Generative AI"                                                         , "Creami qualcosa di simile"         ,
  "Creazione, Generazione nuovi dati (testo, voce, immagini...)"          , #
  "GPT (Transformer), Diffusion Models, GAN, VAE"                         ,
  "ChatGPT, Outlook junk mail, DALL-E, Gemini"                            , # , Copilot Designer, Midjourney, Stable Diffusion

  "AI (orchestrator)"                                                     , "Risolvi questo problema"           ,
  "Orchestrazione multi-strumento"                                        , #
  "Pipeline di ML + reasoning + planning, LLM + Tools + Reasoning"        ,
  "ChatGPT Plus (plugins), Claude (Projects), Perplexity"                 , #, Claude (con tools), Gemini Advanced

  "Agent"                                                                 , "Gestisci questo processo completo" ,
  "Pianificazione ed esecuzione multi-step"                               , #
  "ReAct (Reasoning + Acting), AutoGPT, Task Decomposition"               ,
  " AutoGPT, Microsoft Copilot (autonomous), Zapier AI" #, , n8n AI workflows, Claude Computer Use,LangChain Agents"
)

# Visualizza
# ai_taxonomy

# Oppure con formattazione migliore
ai_taxonomy %>%
  flextable() %>%
  fontsize(size = 22, part = "header") %>% # Header pi√π grande
  fontsize(size = 18, part = "body") %>% # Body della tabella
  bold(part = "header") %>% # Grassetto per l'header
  # Change format of the second & fourth column es_richiesta italics
  flextable::italic(i = NULL, j = c(2, 4), part = "body") %>%
  flextable::color(i = NULL, j = c(2, 4), color = "#9f4136", part = "body") %>%
  # Change background of 1st column to light red
  flextable::bg(i = NULL, j = 1, bg = "#f18b83", part = "body") %>%
  flextable::bold(i = NULL, j = 1, part = "body") %>%
  # Aggiungi footnote alla prima colonna (categoria)
  footnote(
    i = 1,
    j = 1,
    value = as_paragraph("In senso lato tutti questi modelli sono AI"),
    ref_symbols = "*",
    part = "header"
  ) %>%
  # Cambia il testo nei header
  flextable::set_header_labels(
    tipo = "Categoria",
    es_richiesta = "Esempio di richiesta",
    tipo_algoritmo = "Tipo di algoritmo",
    es_algoritmo = "Esempio di output",
    es_brand = "Esempio di piattaforma"
  ) %>%
  autofit()
```

::: {.notes}
+ **Transformers (come GPT)**: predicono il prossimo token in una sequenza, generando testo token per token
+ **GANs**: due reti che "competono" (generator vs discriminator)
+ **VAEs**: codificano dati in spazio latente e poi decodificano
+ **Diffusion models**: partono da rumore e iterativamente lo "denoising" verso l'immagine target
:::


## Esempio pratici calati nell'area erogativa di una fondazione

<!-- Qui metter√≤ una serie di prompts come quelli usati al corso ACRI -->
<br>

::: {style="font-size: 80%;"} 

- **Classificazione di titoli di progetti per settore**
	 - [TIPO: `ML classico`] ‚ûî _etichettatura automatica_
- **Elaborazione di un bando per finanziare corsi STEM**
	 - [TIPO: `AI generativa`]  ‚ûî _bozza di bando_
- **Valutazione e analisi dei progetti presentati**
	 - [TIPO: `AI (orchestrator)`]  ‚ûî _revisione candidature con punteggio_
- **Lancio di sondaggio di soddisfazione tra i beneficiari**
	 - [TIPO: `Agente`]  ‚ûî _questionario creato e distribuito alla lista contatti_

<!-- - Monitoraggio e valutazione dell'impatto dei progetti finanziati -> _sintesi report di monitoraggio_ -->
<!-- 	 - [TIPO: `AI generativa` + `ML classico` ] -->
	 
:::

<!-- - Governance e strategie di adozione dell'IA nelle Fondazioni -->
 
## Cosa \*non\* √® l'IA?

```{r}
#| label: tbl-ia-examples
#| tbl-cap: "Esempi di competenze dell'Intelligenza Umana vs Intelligenza Artificiale"
#| echo: false
#| output: true

library(tibble)
library(flextable)
# Imposta font e dimensione di default per tutte le flextable
set_flextable_defaults(
  font.family = "Roboto Condensed",
  # font.size = 20,
  theme_fun = theme_booktabs
)
# Inserisci come tibble tribble una tabella con 2 colonne e intestazione "Intelligenza umana" "Intelligenza Artificiale", con 5 righe di esempi

tabella_ia <- tribble(
  ~"Competenza"                     , ~"Intelligenza umana" , ~"Intelligenza Artificiale" ,

  "Capisce linguaggio naturale"     , "‚úÖ"                 , "‚òëÔ∏è"                    ,
  "Segue il filo del discorso"      , "‚úÖ"                 , "‚ùå / dipende dal modello" ,
  "Spazia da un contesto all'altro" , "‚úÖ"                 , "‚òëÔ∏è / se aiutata"       ,
  "Ha creativit√† e intuizione"     , "‚úÖ"                 , "‚ùå / imitazione"          ,
  "Gestisce mole enorme di dati"    , "‚ùå"                 , "‚úÖ"
)

tabella_ia %>%
  flextable() %>%
  fontsize(size = 22, part = "header") %>% # Header pi√π grande
  fontsize(size = 18, part = "body") %>% # Body della tabella
  bold(part = "header") %>% # Grassetto per l'header
  autofit()
```

::: {.notes}

1. _`LLMs` Are Prediction Engines, Not Thinking Machines_  -> PRODUCE VERIFIABLE OUTPUTS
2. C'√® un problema di _token limitS_ per cui il bot si dimentica la risposta di prima...
3. 
4. 
5.

:::


## Esempi di "prompt engineering" - DATI

::: {style="font-size: 80%;"}
1. `MINIMO`:  (carico un foglio Excel) Analizza questi dati sulla assistenza ai disabili psichici.
2. `"/" + CONTESTO`: ... √à un trend storico sull‚Äôofferta di assistenza agli adulti con disabilit√† psichica nel territorio di Parma. 
I dati possono contenere errori e record duplicati.
3. `"/" + CONTESTO + OBIETTIVO`: ... L‚Äôobiettivo √® individuare le aree meno servite, identificare momenti di rottura nel tempo e produrre grafici per una presentazione.
4. `"/" + CONTESTO + OBIETTIVO + COLLAB. IA`: ... Che cosa ti serve sapere su questo dataset per aiutarmi a raggiungere questo obiettivo?
5. `"/" + CONTESTO + OBIETTIVO + COLLAB. IA + Conoscenza del dominio`: ... Dare accesso a dati rilevanti
:::

## Esempi di ‚Äúprompt engineering‚Äù ‚Äì BANDO

::: {style="font-size: 80%;"}
1. `MINIMO`:  Scrivi un bando per finanziare servizi a favore dei disabili psichici.
2. `"/" + CONTESTO`: ... Il bando √® promosso da Fondazione Cariparma e riguarda il territorio della provincia di Parma.
3. `"/" + CONTESTO + OBIETTIVO`: ... L‚Äôobiettivo √® rafforzare l‚Äôofferta di servizi per adulti con disabilit√† psichica, in coerenza con il Piano Strategico 2024‚Äì2027, e supportare il Terzo Settore.
4. `"/" + CONTESTO + OBIETTIVO + COLLABORAZIONE IA`: ... Che cosa ti serve sapere (priorit√† strategiche, destinatari, budget, criteri di valutazione) per aiutarmi a disegnarlo in modo efficace?
5. `"/" + CONTESTO + OBIETTIVO + COLLAB. IA + Conoscenza del dominio`: ... Dare accesso a documenti rilevanti (Piano Strategico, linee guida, bandi passati). 
:::

## Panoramica di modelli di IA rilevanti 

- **Generalista**: ChatGPT, Claude, Microsoft Copilot
- **Data Science / Coding Assistant**: GitHub Copilot, Claude Code, ...
- **Ricerca web**: Perplexity, Bing AI 
- **Comunicazione e creativit√†**: ChatGPT, NotebookLM, ZeroGPT, ElevenLabs, HeyGen e Midjourney ...
- **Amministrazione/finanza**:   ...
- **IT e cybersecurity**:   ...
 

## Considerazioni tecniche
::: {style="font-size: 80%;"}
- Questi modelli sono in continua evoluzione
	- E.g. `GPT-2` inventava bibliografie fantastiche, `GPT-4/GPT-5` cercano un confronto pi√π accurato con fonti reali
- Ogni modello/piattaforma ha i suoi punti di forza e limiti
	- `ChatGPT` √® pi√π versatile, `Perplexity` √® meglio nelle ricerche web, `GitHub Copilot` √® specializzato nel codice, `MS Copilot` nasce integrato con Office 365, ecc.
- I modelli di IA possono specializzarsi su un tipo di dato (testo, immagini, audio, video) o essere multimodali (e.g. `GPT-4V`)
- In realt√† adesso moltissimi siti /applicazioni integrano funzionalit√† IA
	- E.g. `Google`, `Grammarly`, `Notion`, `Canva`, ecc.
- Diversit√† di performance in base al piano tariffario
:::

## Considerazioni etiche e di governance

- _Bias_ (~ pregiudizio) intrinseco e/o copertura asimmetrica dei dati
- Trasparenza e spiegabilit√† degli algoritmi
- Privacy e sicurezza dei dati
- Regolamentazione e conformit√†
<!-- - Strategie di adozione responsabile dell'IA -->
- Impatto sul lavoro e sulla societ√†
	- pericolo di _deskilling_ / atrofia cognitiva

## Criteri per circoscrivere il ruolo dell'IA
::: {style="font-size: 70%;"}

- Mi deve supportare nella decisione ma **non prendere decisioni** al mio posto
		- es. valutazione progetti, diagnosi mediche, ecc.
		- non √® semplice come potrebbe sembrare: bias, errori, mancanza di contesto, ecc.

- Decidere in modo intenzionale **per quali compiti** usare l'IA: aspetti noiosi o ripetitivi, compiti che richiedono l'analisi di grandi quantit√† di dati, ma non compiti che richiedono empatia, creativit√† o giudizio etico.		

- **Quali dati** siamo disposti a dare in pasto **a quali modelli di IA**? 
		- Qui entra la scelta del fornitore
		- Garanzie di rispetto della privacy e sicurezza
		- Coerenza con la normativa vigente (GDPR, ecc.)
		
- **Trasparenza**: sapere quando e come viene usata l'IA nei processi decisionali
		- questi algoritmi sono coperti da segreto industriale, quindi non abbiamo accesso al "codice sorgente", per questo non √® accettabile che l'IA prenda decisioni autonome senza supervisione umana
		
:::


## Prossimi passi possibili
::: {style="font-size: 65%;"}
0. [Premesse logiche:] 
	- ottimizzare la gestione dei **documenti/dati esistenti**
	<!-- - avere un budget dedicato all'innovazione digitale / IA -->
	- preparare delle **linee guida** interne sull'uso responsabile dell'IA
	
1. Comprendere le esigenze specifiche della Fondazione per **le varie funzioni** (amministrativo, progettazione, monitoraggio, ecc.):   
	- `Quale problema vorrei risolvere con l'IA?`   
	- `Quale attivit√† potrei automatizzare o migliorare con l'IA?` 
	
2. Stabilire **argini** per salvaguardare funzioni caratterizzanti, sicurezza, ecc.:
	- `Quali funzioni decisionali devono assolutamente restare "umane"?`
	- `Quali standard di sicurezza e privacy sono imprescindibili?`

3. Mappare e valutare le **risorse disponibili** (_make, buy, or partner?_):
	- Sperimentare e valutare piattaforme IA esistenti
	- Collaborare con ACRI e altre Fondazioni
	- Facilitare momenti di formazione condivisione (IA che continua a evolversi), tipo **IA corner** (Fondazione Cariplo)

:::

::: {.notes}
 ‚úÖ **USO REALE e diffuso (anche oltre early adopters):**
1. **Comunicazione e fundraising**
- Bozze newsletter
- Post social media
- Traduzioni (IT‚ÜîEN per progetti EU)
- Riscrittura testi per target diversi (es. stesso progetto ‚Üí versione tecnica vs divulgativa)

**Tool:** ChatGPT, Claude, DeepL (con AI)

2. **Grant management - fase istruttoria**
- Riassunto automatico candidature (centinaia di pagine)
- Estrazione info chiave da application forms
- Primo screening eligibility
- Identificazione red flags

**Tool:** Custom GPT, Claude Projects, alcuni tool specifici italiani (es. alcuni CRM fundraising stanno integrando)

3. **Analisi dati e reportistica**
- Sintesi report di monitoraggio progetti
- Analisi trend su dati beneficiari
- Visualizzazioni dati (con code generation)

**Tool:** ChatGPT Advanced Data Analysis, Claude (con analisi dati)

4. **Knowledge management interno**
- Q&A su documentazione interna
- Ricerca veloce in archivi progetti passati
- Onboarding nuovi dipendenti

**Tool:** Notion AI, Microsoft Copilot (per chi ha M365), custom RAG systems

---

üî¨ **SPERIMENTAZIONE (solo early adopters):**

5. **Valutazione impatto**
- Analisi qualitativa interviste (centinaia di trascrizioni)
- Pattern recognition in feedback beneficiari
- Sentiment analysis su testimonianze

**Problema:** Dati sensibili, serve privacy by design

6. **Matchmaking progetti-finanziatori**
- "Trova fondazioni compatibili con questo progetto"
- "Suggerisci progetti nel portfolio simili a questo nuovo"

**Tool:** Sistemi custom, alcuni vendor stanno sviluppando

7. **Due diligence automatizzata**
- Check reputazione organizzazioni beneficiarie
- Verifica coerenza budget/attivit√†
- Red flags nei bilanci

**Problema:** Rischio di bias, serve validazione umana

---

‚ùå **QUASI ASSENTE (troppo rischioso/complesso):**

8. **Decisioni automatizzate su funding**
- Scoring automatico candidature bandi
‚Üí Troppo rischioso (bias, accountability, trasparenza)

9. **Agenti autonomi**
Es. "Gestisci autonomamente il processo di grant"
‚Üí Nessuno lo sta facendo seriamente
:::

# üü® EXTRA üü®

<!-- # hide a slide -->
## Quarto {visibility="hidden"}

- Footnote ^[the footnote text]
- aside
- speakers notes
- [link](https://quarto.org/docs/presentations/revealjs/advanced.html)
- `Sys.time()`

::: aside
Some additional commentary of more peripheral interest.
:::

::: {.notes}
Speaker notes go here.
:::


## [INS] FT {.notitle}

![](bib/pagine/png/ft.png){.r-stretch}

<br><br>

::: aside
Dal _Financial Times_: `La storia dei Large Language Models (LLM)`, i.e. Deep Learning applicato al linguaggio naturale  
[https://ig.ft.com/generative-ai/](https://ig.ft.com/generative-ai/)

:::

::: {.notes}
Gli LLM sono Deep Learning applicato al linguaggio.
- Gli LLM usano principalmente Transformer (un tipo particolare di rete neurale) invece dei fully connected layers classici
	- Input: parole/token (frammenti di testo)
	- Strati intermedi: estraggono significati, relazioni grammaticali, concetti
	- Output: previsione della prossima parola o risposta completa

:::


## [INS] Captcha {.notitle}

![](bib/pagine/png/accadeva.png){.r-stretch}

::: {.notes}
xxxxx
:::



## Una panoramica di modelli di IA rilevanti 

- Modelli di linguaggio (LLM): GPT-4, PaLM, LLaMA
- Modelli di visione artificiale: DALL-E, Stable Diffusion, Midjourney
- Modelli multimodali: GPT-4V, CLIP
- Modelli specializzati: Codex (programmazione), BioBERT (biomedicina), ecc.
- Modelli open source vs proprietari
- Piattaforme IA: OpenAI, Google Cloud AI, Azure AI, Hugging Face, ecc.
