---
title: "IA nelle Fondazioni Bancarie"
subtitle: "(Resoconto del corso ACRI)"
author: "**Luisa M. Mimmi**<br>(con estratti della presentazione di) **Fabio Fraticelli**"
date: today
date-format: "DD MMMM YYYY"
metadata-files:
  - brand/CRP-revealjs-theme.yml
format: revealjs
  # revealjs:
  #   output-file: presentazione.pdf
  #   pdf-separate-fragments: false
execute:
  echo: true
  include: true
  freeze: auto
---

## Quarto

- Footnote ^[the footnote text]
- aside
- speakers notes
- [link](https://quarto.org/docs/presentations/revealjs/advanced.html)
- `Sys.time()`

::: aside
Some additional commentary of more peripheral interest.
:::

::: {.notes}
Speaker notes go here.
:::

## Programma del corso tenuto il 6/7 Novembre 2025

**L'IA al servizio delle Fondazioni di origine bancaria**

::: {style="font-size: 70%;"}
+ **Giorno 1 (9:30 ‚Äì 17:30)**
	+ Introduzione all‚ÄôIA
	+ IA per analisi del contesto
	+ IA per elaborazione di un bando
	+ IA per la valutazione dei progetti
+ **Giorno 2 (9:00 ‚Äì 13:00)**
	+ IA per Monitoraggio / Valutazione Impatto
	+ Governance e strategie di adozione
	+ Wrap-Up
:::


::: {.notes}
Speaker notes go here.
:::

## [INS] Docente {.notitle}

![](bib/pagine/png/fabio.png){.r-stretch}

 

## A che punto siamo con l'IA?


Tra ottimismo e scetticismo...


<!-- insert to pics side by side -->


![](assets/innov_cycle.png){width="65%"}


## A che punto siamo con l'IA (nelle Fondazioni Bancarie)?

<!-- insert to pics side by side -->
::: {.columns}
::: {.column width="50%"}
![Coffee break in ACRI](assets/caffe.jpg){width="65%"}
:::
::: {.column width="50%"}
![Adozione di IA tra i presenti](assets/sondaggio.jpg){width="65%"}
:::
:::	





# Cosa √® l'Intelligenza Artificiale (IA)?

## [INS] Una storia {.notitle}

![](bib/pagine/png/unastoria.png){.r-stretch}

::: {.notes}
xxxxx
:::
## [INS] MLAI {.notitle}

![](bib/pagine/png/mlai.png){.r-stretch}

::: {.notes}
**Machine learning**: A family of statistical and mathematical modeling techniques that uses a variety
of approaches to automatically learn and improve the prediction of a target state, without explicit
programming

	+ **Computer programming**: The programmer knows what the input and output looks like 	and write code to transform input into output _FUNCTION_ that _processes_ an input and 	_produces_ an output
	
	+ **Machine learning**: The programmer (instead of coding the function) MAY provide 	_EXAMPLES_ of input-output pairs to a learning algorithm that _learns_ a model that 	_approximates_ the transformation from input to output (a.k.a. "training the model")
		- \* hence the importance of exposure to experience / data
	
	+ _SUPERVISED learning_: we provide input and output pairs!!! (a.k.a. the right 	answers), then the MODEL can represent (model) the relationship between input and 	output adjusting a set of numbers (called PARAMETERS: weight, bias....) to minimize 	the error in predicting the output from the input
	+ _UNSUPERVISED learning_: seeks to examine a collection of unlabeled examples and 	group them
	by some notion of shared commonality.

**Deep learning**: Deep learning models are ML models that organize parameters into hierarchical layers. Features (INPUTs) are multiplied and added together repeatedly, with the OUTPUT from one layer of parameters being fed into the next layer ‚Äì before a prediction can be made. 
	+ Il deep learning consente l‚Äôingegnerizzazione automatica delle caratteristiche e raggiunge un‚Äôaccuratezza superiore quando lavora con grandi set di dati.

> In pratica, il DL procede con strati successivi di analisi dei dati (pixel, parole, ecc.), producendo, dopo ogni strato, una rappresentazione intermedia dei dati es. da pixel ‚Üí bordi ‚Üí forme ‚Üí oggetti ‚Üí concetti). Ciascuno strato √® costituito da un insieme di neuroni artificiali, (nodi, i.e. mini modelli predittivi). Ogni strato elabora i dati in ingresso (combinazioni lineari pesate) e produce un output, che viene poi passato come input allo strato successivo ("deep" x i tanti livelli). In conclusione, l'ultimo strato fornisce l'output: un riconoscimento facciale, una diagnosi di patologia, una risposta del call center, la selezione di un candidato HR, l'identificazione di una transazione sospetta, ecc.

:::

## [INS] Reti neurali alla base di `Generative AI` {.notitle}

![](bib/pagine/png/allabase.png){.r-stretch}

::: {.notes}
xxxxx
:::

## Il FT spiega `Generative LLM`

![_Financial Times_: `La storia dei Large Language Models (LLM)` <br>   [https://ig.ft.com/generative-ai/](https://ig.ft.com/generative-ai/)](assets/ft_generative.png) 

<!-- <br><br> -->

<!-- ::: aside -->
<!-- Dal _Financial Times_: `La storia dei Large Language Models (LLM)`, i.e. Deep Learning applicato al linguaggio naturale [https://ig.ft.com/generative-ai/](https://ig.ft.com/generative-ai/) -->

<!-- ::: -->

::: {.notes}
Gli LLM sono Deep Learning applicato al linguaggio.
- Gli LLM usano principalmente **Transformer** (un tipo particolare di rete neurale) invece dei fully connected layers classici
	- Input: parole/token (frammenti di testo)
	- Strati intermedi: estraggono significati, relazioni grammaticali, concetti
	- Output: previsione della prossima parola o risposta completa

+ **Transformers (come GPT)**: predicono il prossimo token in una sequenza, generando testo token per token
:::



## Dal `ML` ad `Agentic AI` (‚úâÔ∏è)

<br> 
```{r}
#| label: ai_taxonomy_1
#| echo: false
#| output: true

library(tibble)
library(flextable)

# Schema ML ‚Üí Generative ‚Üí AI ‚Üí Agent
ai_taxonomy_1 <- tribble(
  ~tipo, ~esempio_richiesta, ~tipo_algoritmo,  ~esempio_email,  ~esempio_brand, 
  
  "ML (classico)",      "Questa email √® spam?", 
  "Classificazione, Predizione, Riconoscimento", #
  "Email ‚Üí classificata come SPAM o NON-SPAM (etichetta)", "Outlook junk mail",
  
  "Generative AI",       "Rispondi a questa email", 
  "Creazione, Generazione nuovi dati", #
  "Email ‚Üí genera bozza di risposta appropriata (tu la invii)", "ChatGPT",
  
  "AI (orchestrator)",       "Gestisci questa richiesta", 
  "Orchestrazione multi-strumento", #
  "Email ‚Üí capisce richiesta, cerca dati necessari nel DB, genera report con allegati (tu rivedi e invii)", "ChatGPT Plus (plugins)",
  
  "Agent",       "Occupati delle email arretrate", 
  "Pianificazione ed esecuzione multi-step", #
  "Email ‚Üí legge, cerca dati, genera report, allega file, INVIA risposta (persegue obiettivi in autonomia!)", "AutoGPT" 
)

# Visualizza
# ai_taxonomy

# Oppure con formattazione migliore
ai_taxonomy_1 %>%
	flextable() %>%
	fontsize(size = 20, part = "header") %>%  # Header pi√π grande
	fontsize(size = 16, part = "body") %>%    # Body della tabella
	bold(part = "header") %>%               # Grassetto per l'header
	# Change format of the second & fourth column es_richiesta italics
	flextable::italic(i = NULL, j = c(2,4), part = "body") %>%
	flextable::color(i = NULL, j = c(2,4), color = "#9f4136", part = "body") %>%
	# Change background of 1st column to light red
	flextable::bg(i = NULL, j = 1, bg = "#f18b83", part = "body") %>%
	flextable::bold(i = NULL, j = c(1,3), part = "body") %>%
	# # Aggiungi footnote alla prima colonna (categoria)
	# footnote(
	# 	i = 1, j = 1,
	# 	value = as_paragraph("In senso lato tutti questi modelli sono AI"),
	# 	ref_symbols = "*",
	# 	part = "header") %>%
	# Cambia il testo nei header
	flextable::set_header_labels(
		tipo = "Categoria",
		esempio_richiesta = "Esempio di richiesta",
		tipo_algoritmo = "Tipo di algoritmo",
		esempio_email = "Esempio di output",
		esempio_brand = "Esempio di piattaforma"
	) %>%
	autofit() 
	
```


::: aside
[In senso lato, sono tutti modelli di **AI**]
:::


::: {.notes}

Perch√© gli agenti sono effettivamente pericolosi:

1. Azioni irreversibili nel mondo reale
	- cancellare database, inviare email a migliaia di persone, fare transazioni finanziarie.
2. Cascate di errori amplificati
	- la query restituisce TUTTI i pazienti, non solo quelli dovuti e fa spam di email
3. Allucinazioni con conseguenze reali
	- inventa dati, numeri di telefono, indirizzi email, ecc.
4. Disallineamento degli obiettivi
	- l'agente interpreta male l'obiettivo e agisce in modi indesiderati
5.  Mancanza di giudizio etico/contestuale
	- non capisce le sfumature sociali, culturali o etiche
	
Come mitigare i rischi:
- Supervisione umana costante ("_human-in-the-loop_")
- Limitare le azioni possibili dell'agente ("_whitelisting_ azioni permesse")
- Validazione e verifica dei risultati ("_checkpoints_ di sicurezza")

:::


## Dal `ML` ad `Agentic AI` (ü§ñ)
<br> 
```{r}
#| label: ai_taxonomy
#| echo: false
#| output: true

library(tibble)
library(flextable)

# Schema ML ‚Üí Generative ‚Üí AI ‚Üí Agent
ai_taxonomy <- tribble(
  ~tipo, ~es_richiesta,  ~tipo_algoritmo,  ~es_algoritmo, ~es_brand,
  
  "ML (classico)",   "Dimmi cos'√® questo", 
  "Classificazione, Predizione, Riconoscimento", #
  "Regressione Logistica, Random Forest, Reti Neurali, XGBoost, SVM",
  "Excel (previsioni), Outlook junk mail, Google Photos (riconoscimento)", # , scikit-learn, tidymodels, caret

  "Generative AI",   "Creami qualcosa di simile", 
  "Creazione, Generazione nuovi dati (testo, voce, immagini...)", #
  "GPT (Transformer), Diffusion Models, GAN, VAE",
  "ChatGPT, Outlook junk mail, DALL-E, Gemini", # , Copilot Designer, Midjourney, Stable Diffusion
  
  "AI (orchestrator)",  "Risolvi questo problema", 
  "Orchestrazione multi-strumento", #
  "Pipeline di ML + reasoning + planning, LLM + Tools + Reasoning",
  "ChatGPT Plus (plugins), Claude (Projects), Perplexity", #, Claude (con tools), Gemini Advanced
  
  "Agent",   "Gestisci questo processo completo", 
  "Pianificazione ed esecuzione multi-step",#
  "ReAct (Reasoning + Acting), AutoGPT, Task Decomposition",
  " AutoGPT, Microsoft Copilot (autonomous), Zapier AI" #, , n8n AI workflows, Claude Computer Use,LangChain Agents"
)

# Visualizza
# ai_taxonomy

# Oppure con formattazione migliore
ai_taxonomy %>%
	flextable() %>%
	fontsize(size = 22, part = "header") %>%  # Header pi√π grande
	fontsize(size = 18, part = "body") %>%    # Body della tabella
	bold(part = "header") %>%               # Grassetto per l'header
	# Change format of the second & fourth column es_richiesta italics
	flextable::italic(i = NULL, j = c(2,4 ), part = "body") %>%
	flextable::color(i = NULL, j = c(2,4 ), color = "#9f4136", part = "body") %>%
	# Change background of 1st column to light red
	flextable::bg(i = NULL, j = 1, bg = "#f18b83", part = "body") %>%
	flextable::bold(i = NULL, j = 1, part = "body") %>%
	# Aggiungi footnote alla prima colonna (categoria)
	footnote(
		i = 1, j = 1,
		value = as_paragraph("In senso lato tutti questi modelli sono AI"),
		ref_symbols = "*",
		part = "header") %>%
		# Cambia il testo nei header
	flextable::set_header_labels(
		tipo = "Categoria",
		es_richiesta = "Esempio di richiesta",
		tipo_algoritmo = "Tipo di algoritmo",
		es_algoritmo = "Esempio di output",
		es_brand = "Esempio di piattaforma"
	) %>%
	autofit() 
```

::: {.notes}
+ **Transformers (come GPT)**: predicono il prossimo token in una sequenza, generando testo token per token
+ **GANs**: due reti che "competono" (generator vs discriminator)
+ **VAEs**: codificano dati in spazio latente e poi decodificano
+ **Diffusion models**: partono da rumore e iterativamente lo "denoising" verso l'immagine target
:::


## Esempio pratici calati nell'area erogativa di una fondazione

<!-- Qui metter√≤ una serie di prompts come quelli usati al corso ACRI -->
<br>

::: {style="font-size: 80%;"} 

- **Classificazione di titoli di progetti per settore**
	 - [TIPO: `ML classico`] ‚ûî _etichettatura automatica_
- **Elaborazione di un bando per finanziare corsi STEM**
	 - [TIPO: `AI generativa`]  ‚ûî _bozza di bando_
- **Valutazione e analisi dei progetti presentati**
	 - [TIPO: `AI (orchestrator)`]  ‚ûî _revisione candidature con punteggio_
- **Lancio di sondaggio di soddisfazione tra i beneficiari**
	 - [TIPO: `Agente`]  ‚ûî _questionario creato e distribuito alla lista contatti_

<!-- - Monitoraggio e valutazione dell'impatto dei progetti finanziati -> _sintesi report di monitoraggio_ -->
<!-- 	 - [TIPO: `AI generativa` + `ML classico` ] -->
	 
:::

<!-- - Governance e strategie di adozione dell'IA nelle Fondazioni -->
 
## Cosa \*non\* √® l'IA?

```{r}
#| label: tbl-ia-examples
#| tbl-cap: "Esempi di competenze dell'Intelligenza Umana vs Intelligenza Artificiale"
#| echo: false
#| output: true



library(tibble)
library(flextable)
# Imposta font e dimensione di default per tutte le flextable
set_flextable_defaults(
  font.family = "Roboto Condensed",
  # font.size = 20,
  theme_fun = theme_booktabs
)
# Inserisci come tibble tribble una tabella con 2 colonne e intestazione "Intelligenza umana" "Intelligenza Artificiale", con 5 righe di esempi

tabella_ia <- tribble(
	~"Competenza", ~"Intelligenza umana", ~"Intelligenza Artificiale",
	
	"Capisce linguaggio naturale",    "‚úÖ", "‚òëÔ∏è",
	"Segue il filo del discorso",     "‚úÖ", "‚ùå / dipende dal modello",
	"Spazia da un contesto all'altro","‚úÖ", "‚òëÔ∏è / se aiutata",
	"Ha creativit√† e intuizione",     "‚úÖ", "‚ùå / imitazione",	
	"Gestisce mole enorme di dati",   "‚ùå", "‚úÖ"
	)

tabella_ia %>%
  flextable() %>%
  fontsize(size = 22, part = "header") %>%  # Header pi√π grande
  fontsize(size = 18, part = "body") %>%    # Body della tabella
	bold(part = "header") %>%               # Grassetto per l'header
  autofit()
```



## Considerazioni tecniche
::: {style="font-size: 80%;"}
- Questi modelli sono in continua evoluzione
	- E.g. `GPT-2` inventava bibliografie fantastiche, `GPT-4/GPT-5` cercano un confronto pi√π accurato con fonti reali
- Ogni modello/piattaforma ha i suoi punti di forza e limiti
	- `ChatGPT` √® pi√π versatile, `Perplexity` √® meglio nelle ricerche web, `GitHub Copilot` √® specializzato nel codice, `MS Copilot` nasce integrato con Office 365, ecc.
- I modelli di IA possono specializzarsi su un tipo di dato (testo, immagini, audio, video) o essere multimodali (e.g. `GPT-4V`)
- In realt√† adesso moltissimi siti /applicazioni integrano funzionalit√† IA
	- E.g. `Google`, `Grammarly`, `Notion`, `Canva```, ecc.
- Diversit√† di performance in base al piano tariffario
:::

## Considerazioni etiche e di governance

- _Bias_ (~ pregiudizio) intrinseco e/o copertura asimmetrica dei dati
- Trasparenza e spiegabilit√† degli algoritmi
- Privacy e sicurezza dei dati
- Regolamentazione e conformit√†
<!-- - Strategie di adozione responsabile dell'IA -->
- Impatto sul lavoro e sulla societ√†
	- pericolo di _deskilling_ 

## Criteri per circoscrivere il ruolo dell'IA
::: {style="font-size: 70%;"}

- Mi deve supportare nella decisione ma **non prendere decisioni** al mio posto
		- es. valutazione progetti, diagnosi mediche, ecc.
		- non √® semplice come potrebbe sembrare: bias, errori, mancanza di contesto, ecc.

- Decidere in modo intenzionale **per quali compiti** usare l'IA: aspetti noiosi o ripetitivi, compiti che richiedono l'analisi di grandi quantit√† di dati, ma non compiti che richiedono empatia, creativit√† o giudizio etico.		

- **Quali dati** siamo disposti a dare in pasto **a quali modelli di IA**? 
		- Qui entra la scelta del fornitore
		- Garanzie di rispetto della privacy e sicurezza
		- Coerenza con la normativa vigente (GDPR, ecc.)
		
- **Trasparenza**: sapere quando e come viene usata l'IA nei processi decisionali
		- questi algoritmi sono coperti da segreto industriale, quindi non abbiamo accesso al "codice sorgente", per questo non √® accettabile che l'IA prenda decisioni autonome senza supervisione umana
		
:::


## Prossimi passi possibili
::: {style="font-size: 75%;"}
0. [Premesse logiche:] 
	- ottimizzare la gestione dei documenti/dati esistenti
	- avere un budget dedicato all'innovazione digitale / IA

1. Comprendere le esigenze specifiche della Fondazione **per le varie funzioni** (amministrativo, progettazione, monitoraggio, ecc.):   
	- `Quale problema vorrei risolvere con l'IA?`   
	- `Quale attivit√† potrei automatizzare o migliorare con l'IA?` 
	
2. Stabilire **argini** per salvaguardare funzioni caratterizzanti, sicurezza, ecc.:
	- `Quali funzioni decisionali devono assolutamente restare "umane"?`
	- `Quali standard di sicurezza e privacy sono imprescindibili?`

3. Mappare e valutare le **risorse disponibili** (_make, buy, or partner?_):
	- Collaborare con ACRI e altre Fondazioni
	- Sperimentare con progetti pilota
	- Creare una task force dedicata all'IA (che continua a evolversi)

:::

::: {.notes}
 ‚úÖ **USO REALE e diffuso (anche oltre early adopters):**
1. **Comunicazione e fundraising**
- Bozze newsletter
- Post social media
- Traduzioni (IT‚ÜîEN per progetti EU)
- Riscrittura testi per target diversi (es. stesso progetto ‚Üí versione tecnica vs divulgativa)

**Tool:** ChatGPT, Claude, DeepL (con AI)

2. **Grant management - fase istruttoria**
- Riassunto automatico candidature (centinaia di pagine)
- Estrazione info chiave da application forms
- Primo screening eligibility
- Identificazione red flags

**Tool:** Custom GPT, Claude Projects, alcuni tool specifici italiani (es. alcuni CRM fundraising stanno integrando)

3. **Analisi dati e reportistica**
- Sintesi report di monitoraggio progetti
- Analisi trend su dati beneficiari
- Visualizzazioni dati (con code generation)

**Tool:** ChatGPT Advanced Data Analysis, Claude (con analisi dati)

4. **Knowledge management interno**
- Q&A su documentazione interna
- Ricerca veloce in archivi progetti passati
- Onboarding nuovi dipendenti

**Tool:** Notion AI, Microsoft Copilot (per chi ha M365), custom RAG systems

---

üî¨ **SPERIMENTAZIONE (solo early adopters):**

5. **Valutazione impatto**
- Analisi qualitativa interviste (centinaia di trascrizioni)
- Pattern recognition in feedback beneficiari
- Sentiment analysis su testimonianze

**Problema:** Dati sensibili, serve privacy by design

6. **Matchmaking progetti-finanziatori**
- "Trova fondazioni compatibili con questo progetto"
- "Suggerisci progetti nel portfolio simili a questo nuovo"

**Tool:** Sistemi custom, alcuni vendor stanno sviluppando

7. **Due diligence automatizzata**
- Check reputazione organizzazioni beneficiarie
- Verifica coerenza budget/attivit√†
- Red flags nei bilanci

**Problema:** Rischio di bias, serve validazione umana

---

‚ùå **QUASI ASSENTE (troppo rischioso/complesso):**

8. **Decisioni automatizzate su funding**
- Scoring automatico candidature bandi
‚Üí Troppo rischioso (bias, accountability, trasparenza)

9. **Agenti autonomi**
Es. "Gestisci autonomamente il processo di grant"
‚Üí Nessuno lo sta facendo seriamente
:::

# üü® EXTRA üü®

## [INS] FT {.notitle}

![](bib/pagine/png/ft.png){.r-stretch}

<br><br>

::: aside
Dal _Financial Times_: `La storia dei Large Language Models (LLM)`, i.e. Deep Learning applicato al linguaggio naturale  
[https://ig.ft.com/generative-ai/](https://ig.ft.com/generative-ai/)

:::

::: {.notes}
Gli LLM sono Deep Learning applicato al linguaggio.
- Gli LLM usano principalmente Transformer (un tipo particolare di rete neurale) invece dei fully connected layers classici
	- Input: parole/token (frammenti di testo)
	- Strati intermedi: estraggono significati, relazioni grammaticali, concetti
	- Output: previsione della prossima parola o risposta completa

:::


## [INS] Captcha {.notitle}

![](bib/pagine/png/accadeva.png){.r-stretch}

::: {.notes}
xxxxx
:::



## Una panoramica di modelli di IA rilevanti 

- Modelli di linguaggio (LLM): GPT-4, PaLM, LLaMA
- Modelli di visione artificiale: DALL-E, Stable Diffusion, Midjourney
- Modelli multimodali: GPT-4V, CLIP
- Modelli specializzati: Codex (programmazione), BioBERT (biomedicina), ecc.
- Modelli open source vs proprietari
- Piattaforme IA: OpenAI, Google Cloud AI, Azure AI, Hugging Face, ecc.
