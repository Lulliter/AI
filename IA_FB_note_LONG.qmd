---
title: "IA nelle Fondazioni Bancarie"
subtitle: "(Resoconto del corso ACRI seguito il 6/7 Novembre 2025)"
author: "**Luisa M. Mimmi**<br>(con estratti della presentazione di) **Fabio Fraticelli**"
date: today
date-format: "DD MMMM YYYY"
metadata-files:
  - brand/CRP-revealjs-theme.yml

format: 
  revealjs: default
  # revealjs:
  #   output-file: presentazione.pdf
  #   pdf-separate-fragments: false
execute:
  echo: true
  include: true
  freeze: auto
lang: it  
---

::: {.content-hidden}     
::: {.notes}
So che c'√® un programma di formazione in vista, quindi questa breve presentazione vuole essere una introduzione. Basandomi sul corso che √® stato molto interessante, vorrei fare una introduzione un po' tra il tecnico e il filosofico che spero possa aiutare - soprattutto chi magari √® pi√π all'inizio - ad approcciarsi in modo sereno a questa specie di onda anomala che ci sta arrivandi in testa... 
:::
::: 

## Programma del corso e docente

<!-- insert to pics side by side -->
::: {.columns}

::: {style="font-size: 70%;"}

::: {.column width="50%"}

+ **Giorno 1 (9:30 ‚Äì 17:30)**
	+ Introduzione all‚ÄôIA
	+ IA per analisi del contesto
	+ IA per elaborazione di un bando
	+ IA per la valutazione dei progetti
+ **Giorno 2 (9:00 ‚Äì 13:00)**
	+ IA per Monitoraggio / Valutazione Impatto
	+ Governance e strategie di adozione
	+ Wrap-Up

:::

::: {.column width="50%"}

**Fabio Fraticelli** 

CEO at SocialTechno / TechSoup Italia

![](assets/docente.png){width="65%"}
:::
:::	
:::


::: {.notes}
Qui potete vedere il programma dei 2 giorni, il docente, F.F. √® stato molto bravo a integrare aspetti pi√π teorici con un po' di esempi pratici... 
:::


## A che punto siamo con l'IA (nelle Fondazioni Bancarie)?

<!-- insert to pics side by side -->
::: {.columns}

::: {.column width="60%"}
![](assets/sondaggio.jpg){width="60%"}
:::

::: {.column width="40%"}

::: {style="font-size: 60%;"}

<br>

<!-- ![Coffee break in ACRI](assets/caffe.jpg){width="65%"} -->
> + **25%** degli europei dichiara di usare l‚ÄôIA generativa **per scopi privati**
> + **15%** degli europei dichiara di usare l‚ÄôIA generativa **per lavoro**

_[Eurobarometer Survey, 2025]_
:::
:::
:::	

::: {.notes}
Vi ho riportato questo sondaggio che √® stato fatto all'inizio: vedete che, tra i presenti, la maggior parte delle persone dice che sta iniziando adesso a sperimentare... 

C'√® un fatto interessante che ci spiega un po' questo ed √® il divario che c'√® tra l'utilizzo privato - molto pi√π importante - e quello sul lavoro - evidentemente anche frenato da vincoli di sicurezza ecc. 
:::

# Cosa √® l'Intelligenza Artificiale (IA)?

<!-- ## [INS] Un lavoro di oltre 70 anni {.notitle} -->

<!-- ![](bib/pagine/png/unastoria.png){.r-stretch} -->

<!-- ::: {.notes} -->
<!-- xxxxx -->
<!-- ::: -->

## Una storia di oltre 70 anni

![](assets/AI_booms.png){.r-stretch}

::: {.notes}
https://news.skhynix.com/all-about-ai-the-origins-evolution-future-of-ai/
https://www.workday.com/it-it/topics/ai/agentic-ai.html

1. Negli anni ‚Äô50 compare l‚Äô`intelligenza artificiale come concetto` quando nel 1950 _Alan Turing_ propose che le macchine potessero ‚Äúpensare‚Äù e sugger√¨ un test per valutarlo. Nel 1956 la conferenza di Dartmouth coni√≤ per la prima volta il termine "AI", e furono sviluppati i primi modelli di `rete neurale`, come il `perceptron` di _Frank Rosenblatt_ basato sulle teorie di McCulloch e Pitts.
	- **Perceptron** = The simplest form of a neural network. It is a model of a single neuron that can be used for binary classification problems, enabling it to determine whether an input belongs to one class or another.  

2. Nonostante iniziali difficolt√† e periodi di stagnazione, dagli anni ‚Äô80 l‚Äôintroduzione del `backpropagation` (`multilayer perceptron di Hinton`) ha reso possibile addestrare reti neurali pi√π profonde e complesse; e con pi√π dati e pi√π potenza di calcolo, il `deep learning` ha permesso alle reti neurali di superare molti limiti precedenti e di ottenere prestazioni nettamente superiori in compiti reali.
	+ **Backpropagation**: An algorithm used in neural networks to minimize errors by adjusting the weights. It works by calculating the difference between the predicted and actual values and then updating the weights in reverse order, starting from the output layer.

3. Big data e Internet: Con l‚Äôavvento del digitale e della rete negli anni ‚Äô90, l‚ÄôIA pot√© accedere a enormi quantit√† di dati: il `‚Äúbig data‚Äù` e la maggiore `capacit√† di calcolo (GPU e Internet)` permisero all‚Äôapprendimento automatico di scoprire schemi autonomamente e migliorare notevolmente i suoi risultati su problemi complessi.

4. Alla fine del 2022 OpenAI ha lanciato ChatGPT, basato sui modelli `generative pre-trained transformer (GPT)`. Questo ha segnato l‚Äôinizio dell‚Äôera dell‚ÄôIA generativa, capace non solo di analizzare dati ma di produrre contenuti originali in linguaggio naturale con un‚Äôampia gamma di applicazioni. ChatGPT ha trasformato la percezione pubblica dell‚ÄôIA e acelerato l‚Äôadozione di modelli linguistici avanzati.

	+ **Large language model (LLM)**: `Deep learning` algorithms that perform a variety of natural language processing tasks by leveraging extensive data.
	+ **Large Multimodal Model (LMM)**: A deep learning algorithm that can handle many types of data, including images, audio, and more, not just text.

:::


## La rivoluzione: Deep Neural Networks

<!-- ![](assets/Neuron.png){.absolute left=0 width="30%"} -->
 
:::: {style="font-size: 50%;"} 
**Algoritmo con vari strati** costituiti da `neuroni` (i.e. mini modelli predittivi), che confronta l'**output finale** con esempi noti e **si "adatta"** per minimizzare l'errore. 
<!-- Forward propagation (andata e previsione)
Backpropagation l‚Äôerrore finale viene fatto retrocedere strato per strato, e in ciascuno strato vengono aggiornati tutti i pesi dei neuroni.  ottimizzato con `gradient descent`. -->
<!-- + `deep learning`, si riferisce al N. di strati -->

+ Esempio 1): `pixel ‚Üí bordi ‚Üí forme complesse ‚Üí oggetti ‚Üí personaggio`
+ Esempio 2): `token ‚Üí peso emotivo ‚Üí relazione tra parole ‚Üí Sentimento Positiva/Negativa`
::::


![](assets/DeepLearning.jpg){.absolute width="70%"}
 

<!-- ## [INS] Reti neurali alla base di `Generative AI` {.notitle} -->
<!-- ![](bib/pagine/png/allabase.png){.r-stretch} -->
<!-- Datapizza : ret neurali https://www.youtube.com/watch?v=H8r8aGFBnXk -->

::: {.notes}
LEGGO IL GRAFICO

Gli LLM sono Deep Learning applicato al linguaggio.
- Gli LLM usano principalmente **Transformer** (un tipo particolare di rete neurale) invece dei fully connected layers classici
	- Input: parole/token (frammenti di testo)
	- Strati intermedi: estraggono significati, relazioni grammaticali, concetti
	- Output: previsione della prossima parola o risposta completa

+ **Transformers (come GPT)**: predicono il prossimo token in una sequenza, generando testo token per token

+ Transformers generano **embeddings**: rappresentazioni numeriche di parole/frasi che catturano il loro significato e contesto, permettendo al modello di "comprendere" relazioni semantiche.
:::


## La Gen AI √® solo una parte

<!-- https://k21academy.com/ai-ml/what-is-generative-ai/ -->

::: {columns}

::: {.column width="40%"}

::: {style="font-size: 60%;"}

<br>

**AI**: Insieme di tecniche che svolgono compiti tipici dell'intelligenza umana
<!-- (ragionamento, apprendimento, comprensione del linguaggio naturale, ecc.) -->

**ML**: Modelli allenati su dati senza istruzioni esplicite ‚Äî riconoscono pattern, fanno previsioni
<!-- viene meno la distinzione tra programmazione tradizionale e apprendimento automatico -->

**DL**: Reti neurali multi-strato che estraggono caratteristiche complesse dai dati
<!-- Questo strati successivi che estraggono caratteristiche e un algoritmo che aggiusta i pesi con backpropagation + gradient descent ‚Äî √® la base di tutta l‚ÄôIA neurale moderna, sia:  DISCRIMINATIVA CHE GENERATIVA (se aggiungi un livello di decodifica che produce ...) -->

**GenAI**: Invece che output predefiniti, creano nuovi contenuti (testo, immagini, audio) simili ai dati di addestramento
<!-- ‚ÄúAll‚Äôaumentare della complessit√† ‚Äî dal machine learning tradizionale al deep learning, fino alla generative AI ‚Äî crescono anche i costi: servono molti pi√π dati, modelli molto pi√π grandi e una capacit√† di calcolo enormemente superiore per addestrarli e mantenerli operativi.‚Äù -->

**[Agentic AI]{style="color: #b27d2c;"}** : GenAI a cui si aggiunge capacit√† di pianificazione ed esecuzione autonoma di compiti complessi

:::
:::

::: {.column width="55%"}
![](assets/AI_bubbles.png)
:::

:::

::: {.notes}
- **Computer programming** : The programmer knows what the input and output looks like and write code to transform input into output _FUNCTION_ that _processes_ an input and _produces_ an output
	
- **Machine learning** : The programmer (instead of coding the function) MAY provide 	_EXAMPLES_ of input-output pairs to a learning algorithm that _learns_ a model that 	_approximates_ the transformation from input to output (a.k.a. "training the model") --  hence the importance of exposure to experience / data
	
	+ _SUPERVISED learning_ : we provide input and output pairs!!! (a.k.a. the right 	answers), then the MODEL can represent (model) the relationship between input and 	output adjusting a set of numbers (called PARAMETERS: weight, bias....) to minimize 	the error in predicting the output from the input
	+ _UNSUPERVISED learning_ : seeks to examine a collection of unlabeled examples and 	group them
	by some notion of shared commonality.

- **Deep learning**: Deep learning models are ML models that organize parameters into hierarchical layers. Features (INPUTs) are multiplied and added together repeatedly, with the OUTPUT from one layer of parameters being fed into the next layer ‚Äì before a prediction can be made.
	+ Il deep learning consente l‚Äôingegnerizzazione automatica delle caratteristiche e raggiunge un‚Äôaccuratezza superiore quando lavora con grandi set di dati.

> In pratica, il DL procede con strati successivi di analisi dei dati (pixel, parole, ecc.), producendo, dopo ogni strato, una rappresentazione intermedia dei dati es. da pixel ‚Üí bordi ‚Üí forme ‚Üí oggetti ‚Üí concetti). Ciascuno strato √® costituito da un insieme di **neuroni** artificiali, (nodi, i.e. mini modelli predittivi). Ogni strato elabora i dati in ingresso (combinazioni lineari pesate) e produce un **output** intermedio, che viene poi passato come input allo strato successivo ("deep" x i tanti livelli). In conclusione, l'ultimo strato fornisce l'**output**: un riconoscimento facciale, una diagnosi di patologia, una risposta del call center, la selezione di un candidato HR, l'identificazione di una transazione sospetta, ecc.

:::

##  Gestione email ‚úâÔ∏è: da `ML` ad `Agentic AI` 
<br>

```{r}
#| label: ai_taxonomy_1
#| echo: false
#| output: true

library(tibble)
library(flextable)

# Schema ML ‚Üí Generative ‚Üí AI ‚Üí Agent
ai_taxonomy_1 <- tribble(
  ~tipo                                                                                                        , ~esempio_richiesta               , ~tipo_algoritmo , ~esempio_email , ~esempio_brand ,

  "ML (classico)"                                                                                              , "Questa email √® spam?"          ,
  "Classificazione, Predizione, Riconoscimento"                                                                , #
  "Email ‚Üí classificata come SPAM o NON-SPAM"                                                    , "Casella \"Posta Indesiderata\""              ,

  "Generative AI"                                                                                              , "Rispondi a questa email"        ,
  "Creazione, Generazione nuovi dati"                                                                          , #
  "Email ‚Üí genera bozza di risposta appropriata"                                               , "ChatGPT"                        ,

  # "AI (orchestrator)"                                                                                          , "Gestisci questa richiesta"      ,
  # "Orchestrazione multi-strumento"                                                                             , #
  # "Email ‚Üí capisce richiesta, cerca dati necessari nel DB, genera report con allegati (tu rivedi e invii)"   , "ChatGPT Plus (plugins)"         ,

  "Agentic AI"                                                                                                      , "Gestisci le email arretrate" ,
  "Pianificazione ed esecuzione multi-step"                                                                    , #
  "Email ‚Üí legge, cerca dati, genera report, allega file, INVIA risposta (in autonomia!)" , "Gmail+Gemini o Outlook+MS Copilot"
)

# Visualizza
# ai_taxonomy

# Oppure con formattazione migliore
ai_taxonomy_1 %>%
  flextable() %>%
  fontsize(size = 20, part = "header") %>% # Header pi√π grande
  fontsize(size = 16, part = "body") %>% # Body della tabella
  bold(part = "header") %>% # Grassetto per l'header
  # Change format of the second & fourth column es_richiesta italics
  flextable::italic(i = NULL, j = c(2, 4), part = "body") %>%
  flextable::color(i = NULL, j = c(2, 4), color = "#9f4136", part = "body") %>%
  # Change background of 1st column to light red
  flextable::bg(i = NULL, j = 1, bg = "#f18b83", part = "body") %>%
  flextable::bold(i = NULL, j = c(1, 3), part = "body") %>%
  # # Aggiungi footnote alla prima colonna (categoria)
  # footnote(
  # 	i = 1, j = 1,
  # 	value = as_paragraph("In senso lato tutti questi modelli sono AI"),
  # 	ref_symbols = "*",
  # 	part = "header") %>%
  # Cambia il testo nei header
  flextable::set_header_labels(
    tipo = "Categoria IA",
    esempio_richiesta = "Richiesta",
    tipo_algoritmo = "Tipo di algoritmo",
    esempio_email = "Output",
    esempio_brand = "Strumento"
  ) %>%
  autofit() 
	

```


::: aside
[In senso lato, sono tutti modelli di **AI**]
:::


::: {.notes}
Per portare questi alagoritmi vicino a noi ... vediamo il caso della gestione delle email

Partiamo da qualcosa che usiamo gi√† da tempo: _CAsella indesiderata_: non √® altro che un modello di ML che classifica le email

...poi passiamo alla _Gen AI_ che ci pu√≤ preparare una bozza... di cui per√≤ siamo noi a disporre

... da ultimo, la _GEN AI_ fa invece un enorme salto in avanti per 2 motivi: 1) che c'√® un mandato 2) che deve necessariamente avere accesso ai miei dati 3) che c'√® un'orchestrazione di modelli

**Perch√© gli agenti sono effettivamente pericolosi:**

1. Azioni irreversibili nel mondo reale
	- cancellare database, inviare email a migliaia di persone, fare transazioni finanziarie.
2. Cascate di errori amplificati
	- la query restituisce TUTTI i pazienti, non solo quelli dovuti e fa spam di email
3. Allucinazioni con conseguenze reali
	- inventa dati, numeri di telefono, indirizzi email, ecc.
4. Disallineamento degli obiettivi
	- l'agente interpreta male l'obiettivo e agisce in modi indesiderati
5.  Mancanza di giudizio etico/contestuale
	- non capisce le sfumature sociali, culturali o etiche
	
**Come mitigare i rischi:**
- Supervisione umana costante (" _human-in-the-loop_ ")
- Limitare le azioni possibili dell'agente (" _whitelisting_ azioni permesse")
- Validazione e verifica dei risultati (" _checkpoints_ di sicurezza")
:::


## Esempio pratici calati nell'area erogativa di una fondazione

<!-- Qui metter√≤ una serie di prompts come quelli usati al corso ACRI -->
<br>

::: {style="font-size: 80%;"} 

- **Classificazione di titoli di progetti per settore**
	 - [TIPO: `ML classico`] ‚ûî _etichettatura automatica_
- **Elaborazione di un bando per finanziare corsi STEM**
	 - [TIPO: `AI generativa`]  ‚ûî _bozza di bando_
<!-- - **Valutazione e analisi dei progetti presentati** -->
<!-- 	 - [TIPO: `AI (orchestrator)`]  ‚ûî _revisione candidature con punteggio_ -->
- **Lancio di sondaggio di soddisfazione tra i beneficiari**
	 - [TIPO: `AI Agente`]  ‚ûî _questionario creato e distribuito alla lista contatti_

<!-- - Monitoraggio e valutazione dell'impatto dei progetti finanziati -> _sintesi report di monitoraggio_ -->
<!-- 	 - [TIPO: `AI generativa` + `ML classico` ] -->
	 
:::

<!-- - Governance e strategie di adozione dell'IA nelle Fondazioni -->
 
## Cosa \*non\* √® l'IA?
<br>
```{r}
#| label: tbl-ia-examples
#| tbl-cap: "Esempi di competenze dell'Intelligenza Umana vs Intelligenza Artificiale"
#| echo: false
#| output: true

library(tibble)
library(flextable)
# Imposta font e dimensione di default per tutte le flextable
set_flextable_defaults(
  font.family = "Roboto Condensed",
  # font.size = 20,
  theme_fun = theme_booktabs
)
# Inserisci come tibble tribble una tabella con 2 colonne e intestazione "Intelligenza umana" "Intelligenza Artificiale", con 5 righe di esempi

tabella_ia <- tribble(
  ~"Competenza"                     , ~"Intelligenza umana" , ~"\"Intelligenza\" Artificiale" ,

  "1. Capisce linguaggio naturale"     , "‚úÖ"                 , "‚òëÔ∏è"                    ,
  "2. Segue il filo del discorso (memoria)", "‚úÖ"            , "‚ùå / dipende dal modello" ,
  "3. Spazia da un contesto all'altro" , "‚úÖ"                 , "‚òëÔ∏è / se aiutata"       ,
  "4. Ha creativit√† e intuizione"     , "‚úÖ"                 , "‚ùå / imitazione"          ,
  "5. Gestisce mole enorme di dati"    , "‚ùå"                 , "‚úÖ"
)

tabella_ia %>%
  flextable() %>%
  fontsize(size = 22, part = "header") %>% # Header pi√π grande
  fontsize(size = 18, part = "body") %>% # Body della tabella
  bold(part = "header") %>% # Grassetto per l'header
  autofit()
```

::: {.notes}

1. _`LLMs` Are Prediction Engines, Not Thinking Machines_  -> PRODUCE VERIFIABLE OUTPUTS
L'IA non sta capendo la realt√† sottesa al linguaggio, ma riconosce pattern statistici appresi nei testi di addestramento
2. il cervello ha una _memoria_ che non √® solo "archivio" ma √® una interpretazione dinamica, L'AI ha un problema di _token limits_ dentro un contesto disponibile per cui il bot si dimentica la risposta di prima...
3. il cervello umano generalizza attraverso il _ragionamento astratto_; l‚ÄôAI trasferisce competenze con una _generalizzazione statistica_: quindi  _solo se trova analogie nei dati o se riceve istruzioni esplicite_, quindi il passaggio non √® spontaneo.
4. l‚Äôintuizione umana nasce da esperienza, emozioni e obiettivi; l‚ÄôAI combina elementi gi√† visti secondo probabilit√†, producendo novit√† apparenti ma senza intenzionalit√†.
5. il cervello umano ha limiti biologici di attenzione e capacit√† di elaborazione ‚Äî compensati per√≤ da maggiore efficienza interpretativa.

:::


## Esempi di "prompt engineering" - DATI

::: {style="font-size: 80%;"}
1. `MINIMO`:  (carico un foglio Excel) Analizza questi dati sulla assistenza ai disabili psichici.
2. `"/" + CONTESTO`: ... √à un trend storico sull‚Äôofferta di assistenza agli adulti con disabilit√† psichica nel territorio di Parma. 
I dati possono contenere errori e record duplicati.
3. `"/" + CONTESTO + OBIETTIVO`: ... L‚Äôobiettivo √® individuare le aree meno servite, identificare momenti di rottura nel tempo e produrre grafici per una presentazione.
4. `"/" + CONTESTO + OBIETTIVO + COLLAB. IA`: ... Che cosa ti serve sapere su questo dataset per aiutarmi a raggiungere questo obiettivo?
5. `"/" + CONTESTO + OBIETTIVO + COLLAB. IA + Conoscenza del dominio`: ... Dare accesso a dati rilevanti
:::

## Esempi di ‚Äúprompt engineering‚Äù ‚Äì BANDO

::: {style="font-size: 80%;"}
1. `MINIMO`:  Scrivi un bando per finanziare servizi a favore dei disabili psichici.
2. `"/" + CONTESTO`: ... Il bando √® promosso da Fondazione Cariparma e riguarda il territorio della provincia di Parma.
3. `"/" + CONTESTO + OBIETTIVO`: ... L‚Äôobiettivo √® rafforzare l‚Äôofferta di servizi per adulti con disabilit√† psichica, in coerenza con il Piano Strategico 2024‚Äì2027, e supportare il Terzo Settore.
4. `"/" + CONTESTO + OBIETTIVO + COLLABORAZIONE IA`: ... Che cosa ti serve sapere (priorit√† strategiche, destinatari, budget, criteri di valutazione) per aiutarmi a disegnarlo in modo efficace?
5. `"/" + CONTESTO + OBIETTIVO + COLLAB. IA + Conoscenza del dominio`: ... Dare accesso a documenti rilevanti (Piano Strategico, linee guida, bandi passati). 
:::

## Panoramica di modelli di IA rilevanti 

:::: {.columns}

::: {.column width="65%"}

::: {style="font-size: 75%;"}
<br>

- **Generalista**: ChatGPT, Claude, Google Gemini
- **Produttivit√†**: Microsoft 365 Copilot, Notion AI, Otter.ai, ...
- **Codice & analisi dati**: GitHub Copilot, Claude Code, Cursor
- **Ricerca web**: Perplexity, Bing AI 
- **Comunicazione e creativit√†**: NotebookLM, ZeroGPT, ElevenLabs, HeyGen e Midjourney 
::: 

:::

::: {.column width="10%"}
<!-- ![](assets/topAI.png) -->

:::

::: {.column width="25%"}
![](assets/topAI.png)

:::
::::


::: {.notes}
Non ho assolutamente la pretesa di stendere una lista esaustiva, ma solo segnalare che ci sono molti modelli diversi e che vanno scelti in base al compito che si vuole svolgere--- guarda caso sono distribuiti dai soliti sospetti... 
:::
 

## Considerazioni tecniche
::: {style="font-size: 80%;"}
- Questi modelli sono in **continua evoluzione**
	- E.g. `GPT-2` inventava bibliografie, `GPT-4/GPT-5` cerca fonti reali
- Ogni modello/piattaforma √® **"specializzato"** su funzione o tipo di dato
	- `ChatGPT` - versatile, `Perplexity` - ricerche web, `GitHub Copilot` - codice, `MS Copilot` - Office 365, ecc.
- Moltissime **applicazioni gi√† integrano funzionalit√† IA** in sottofondo
	- E.g. `Gmail autocomplete`, `Google Maps` che prevede il traffico, `Spotify` che impara i gusti, ecc.
- Diversit√† di performance in base al **piano tariffario**!

:::

## Considerazioni etiche e di governance

::: {style="font-size: 70%;"}
- **Pregiudizio** (~_bias_) intrinseco e/o copertura asimmetrica dei dati
- **Trasparenza** e spiegabilit√† degli algoritmi (_black box_)
- **Privacy e sicurezza**  dei dati sensibili
- **Regolamentazione** e conformit√†: quadro normativo in rapida evoluzione (e.g. AI Act)
<!-- - Strategie di adozione responsabile dell'IA -->
- **Impatto** sul lavoro e sulla societ√†
	- automazione v. pericolo di _deskilling_ / atrofia cognitiva
	
:::

::: {.notes}
Qui secondo me, se uno ha capito un po' di cosa si tratta, queste considerazioni poi sono piuttosto ovvie: il punto secondo me √® che c'√® una fase in cui ci si fa prendere dall'entusiasmo e si arischi di abbassare il livello di guardia... 

E poi ci sono aspetti che sono tutti da vedere ma che vanno tenuti in considerazione... 
es. dashboard... ma vale la pena imparare a farle? 

---

+ Bias nei dati ‚Üí rischio di decisioni distorte
	_Nota_: i modelli apprendono dai dati storici; se questi contengono squilibri o pregiudizi, possono replicarli su larga scala.

+ Trasparenza ‚Üí modelli spesso poco spiegabili (‚Äúblack box‚Äù)
Nota: in alcuni casi √® difficile capire perch√© un sistema abbia prodotto una certa risposta, e questo pu√≤ complicare fiducia e accountability.

+ Privacy e sicurezza ‚Üí uso e protezione dei dati sensibili
	_Nota_: pi√π l‚ÄôAI √® integrata nei processi, pi√π diventa cruciale sapere quali dati vengono raccolti, dove sono conservati e come vengono utilizzati.

+ Regole e conformit√† ‚Üí quadro normativo in rapida evoluzione
	_Nota_: le organizzazioni devono adattarsi rapidamente a nuove linee guida e responsabilit√†, spesso mentre la tecnologia continua a cambiare.

+ Impatto su lavoro e societ√† ‚Üí automazione vs perdita di competenze (deskilling)
	_Nota_: l‚ÄôAI pu√≤ aumentare la produttivit√†, ma se usata in modo passivo rischia di ridurre esercizio del pensiero critico e autonomia professionale.
:::


## Criteri per circoscrivere il ruolo dell'IA
::: {style="font-size: 70%;"}

- **Supporto, non sostituzione**: l‚ÄôAI deve informare le decisioni, non prenderle in autonomia ‚Äî soprattutto in _compiti decisivi_ per mandato o reputazione dell'ente.

- **Uso intenzionale**: ideale per attivit√† ripetitive o _data-intensive_; no in compiti che richiedono empatia, creativit√† o giudizio etico.

- **Gestione dei dati in condivisione**: con quali modelli/ fornitori/ garanzie di privacy, sicurezza e conformit√† normativa (GDPR, AI Act, ecc.).

- **Supervisione e trasparenza**: sapere quando l‚ÄôAI entra nei processi e mantenere sempre una responsabilit√† umana.
:::


## Prossimi passi possibili
::: {style="font-size: 65%;"}
0. [**Premesse** logiche:] 
	- ottimizzare la gestione/archiviazione dei **documenti/dati esistenti**
	<!-- - avere un budget dedicato all'innovazione digitale / IA -->
	- preparare delle **linee guida** interne sull'uso responsabile dell'IA
	
1. Mappare esigenze specifiche per **funzioni** (amministrativo, progettazione, monitoraggio, ecc.):   
	- _"Quale problema vorrei risolvere con l'IA?"_   
	- _"Quale attivit√† potrei automatizzare o migliorare con l'IA?"_ 
	
2. Stabilire **argini** per salvaguardare funzioni caratterizzanti, sicurezza, ecc.:
	- _"Quali funzioni decisionali devono assolutamente restare "umane"?"_
	- _"Quali standard di sicurezza e privacy sono imprescindibili?"_

3. Valutare le **opzioni disponibili**:
	- Test parziali con piattaforme IA esistenti
	- Formazione (ACRI, altre Fondazioni, consulenti...)
	- Condivisione periodica, tipo **IA corner** (Fondazione Cariplo)

:::

::: {.notes}
 ‚úÖ **USO REALE e diffuso (anche oltre early adopters):**
1. **Comunicazione e fundraising**
- Bozze newsletter
- Post social media
- Traduzioni (IT‚ÜîEN per progetti EU)
- Riscrittura testi per target diversi (es. stesso progetto ‚Üí versione tecnica vs divulgativa)

**Tool:** ChatGPT, Claude, DeepL (con AI)

2. **Grant management - fase istruttoria**
- Riassunto automatico candidature (centinaia di pagine)
- Estrazione info chiave da application forms
- Primo screening eligibility
- Identificazione red flags

**Tool:** Custom GPT, Claude Projects, alcuni tool specifici italiani (es. alcuni CRM fundraising stanno integrando)

3. **Analisi dati e reportistica**
- Sintesi report di monitoraggio progetti
- Analisi trend su dati beneficiari
- Visualizzazioni dati (con code generation)

**Tool:** ChatGPT Advanced Data Analysis, Claude (con analisi dati)

4. **Knowledge management interno**
- Q&A su documentazione interna
- Ricerca veloce in archivi progetti passati
- Onboarding nuovi dipendenti

**Tool:** Notion AI, Microsoft Copilot (per chi ha M365), custom RAG systems

---

üî¨ **SPERIMENTAZIONE (solo early adopters):**

5. **Valutazione impatto**
- Analisi qualitativa interviste (centinaia di trascrizioni)
- Pattern recognition in feedback beneficiari
- Sentiment analysis su testimonianze

**Problema:** Dati sensibili, serve privacy by design

6. **Matchmaking progetti-finanziatori**
- "Trova fondazioni compatibili con questo progetto"
- "Suggerisci progetti nel portfolio simili a questo nuovo"

**Tool:** Sistemi custom, alcuni vendor stanno sviluppando

7. **Due diligence automatizzata**
- Check reputazione organizzazioni beneficiarie
- Verifica coerenza budget/attivit√†
- Red flags nei bilanci

**Problema:** Rischio di bias, serve validazione umana

---

‚ùå **QUASI ASSENTE (troppo rischioso/complesso):**

8. **Decisioni automatizzate su funding**
- Scoring automatico candidature bandi
‚Üí Troppo rischioso (bias, accountability, trasparenza)

9. **Agenti autonomi**
Es. "Gestisci autonomamente il processo di grant"
‚Üí Nessuno lo sta facendo seriamente
:::


## Alcune risorse utili

::: {style="font-size: 70%;"} 

+ Fondazione Cariplo e Microsoft collaborano al prgramma `Good Loop` - **L'Academy AI per il Terzo Settore** [https://cariplofactory.it/progetto/good-loop/](https://cariplofactory.it/progetto/good-loop/)

+ Datapizza, video YT su  `Che cos‚Äô√® l'Intelligenza Artificiale? - Guida Completa Base` [https://www.youtube.com/watch?v=I-PldL2o1QM](https://www.youtube.com/watch?v=I-PldL2o1QM)

+ Jeff Su, video YT su `Top 6 AI Trends That Will Define 2026` [https://www.youtube.com/watch?v=B23W1gRT9eY](https://www.youtube.com/watch?v=B23W1gRT9eY)

+ Il Financial Times spiega `Generative LLM` con **Visual Storytelling** [https://ig.ft.com/generative-ai/](https://ig.ft.com/generative-ai/)

+ Alberto Puliafito mostra `Come si personalizza un'intelligenza artificiale? - ChatGPT` (**focus su giornalismo**) [https://www.youtube.com/watch?v=Xxqs-MyXdjY&t=78s](https://www.youtube.com/watch?v=Xxqs-MyXdjY&t=78s)


:::


<!-- ![_Financial Times_: `La storia dei Large Language Models (LLM)` <br>   [https://ig.ft.com/generative-ai/](https://ig.ft.com/generative-ai/)](assets/ft_generative.png)  -->

<!-- <br><br> -->

<!-- ::: aside -->
<!-- Dal _Financial Times_: `La storia dei Large Language Models (LLM)`, i.e. Deep Learning applicato al linguaggio naturale [https://ig.ft.com/generative-ai/](https://ig.ft.com/generative-ai/) -->

<!-- ::: -->





# üü® EXTRA üü®

## Quarto {visibility="hidden"}

- Footnote ^[the footnote text]
- aside
- speakers notes
- [link](https://quarto.org/docs/presentations/revealjs/advanced.html)
- `Sys.time()`

::: aside
Some additional commentary of more peripheral interest.
:::

::: {.notes}
Speaker notes go here.
:::

## A che punto siamo con l'IA?


Tra ottimismo e scetticismo...


<!-- insert to pics side by side -->


![](assets/innov_cycle.png){width="65%"}



<!-- # hide a slide -->
## Dal `ML` ad `Agentic AI` (ü§ñ)

```{r}
#| label: ai_taxonomy
#| echo: false
#| output: true

library(tibble)
library(flextable)

# Schema ML ‚Üí Generative ‚Üí AI ‚Üí Agent
ai_taxonomy <- tribble(
  ~tipo                                                                   , ~es_richiesta                       , ~tipo_algoritmo , ~es_algoritmo , ~es_brand ,

  "ML (classico)"                                                         , "Dimmi cos'√® questo"               ,
  "Classificazione, Predizione, Riconoscimento"                           , #
  "Regressione Logistica, Random Forest, Reti Neurali, XGBoost, SVM"      ,
  "Excel (previsioni), Outlook junk mail, Google Photos (riconoscimento)" , # , scikit-learn, tidymodels, caret

  "Generative AI"                                                         , "Creami qualcosa di simile"         ,
  "Creazione, Generazione nuovi dati (testo, voce, immagini...)"          , #
  "GPT (Transformer), Diffusion Models, GAN, VAE"                         ,
  "ChatGPT, Outlook junk mail, DALL-E, Gemini"                            , # , Copilot Designer, Midjourney, Stable Diffusion

  # "AI (orchestrator)"                                                     , "Risolvi questo problema"           ,
  # "Orchestrazione multi-strumento"                                        , #
  # "Pipeline di ML + reasoning + planning, LLM + Tools + Reasoning"        ,
  # "ChatGPT Plus (plugins), Claude (Projects), Perplexity"                 , #, Claude (con tools), Gemini Advanced

  "Agentic AI"                                                            , "Gestisci questo processo completo" ,
  "Pianificazione ed esecuzione multi-step"                               , #
  "ReAct (Reasoning + Acting), AutoGPT, Task Decomposition"               ,
  " AutoGPT, Microsoft Copilot (autonomous), Zapier AI" #, , n8n AI workflows, Claude Computer Use,LangChain Agents"
)

# Visualizza
# ai_taxonomy

# Oppure con formattazione migliore
ai_taxonomy %>%
  flextable() %>%
  fontsize(size = 22, part = "header") %>% # Header pi√π grande
  fontsize(size = 18, part = "body") %>% # Body della tabella
  bold(part = "header") %>% # Grassetto per l'header
  # Change format of the second & fourth column es_richiesta italics
  flextable::italic(i = NULL, j = c(2, 4), part = "body") %>%
  flextable::color(i = NULL, j = c(2, 4), color = "#9f4136", part = "body") %>%
  # Change background of 1st column to light red
  flextable::bg(i = NULL, j = 1, bg = "#f18b83", part = "body") %>%
  flextable::bold(i = NULL, j = 1, part = "body") %>%
  # Aggiungi footnote alla prima colonna (categoria)
  footnote(
    i = 1,
    j = 1,
    value = as_paragraph("In senso lato tutti questi modelli sono AI"),
    ref_symbols = "*",
    part = "header"
  ) %>%
  # Cambia il testo nei header
  flextable::set_header_labels(
    tipo = "Categoria",
    es_richiesta = "Esempio di richiesta",
    tipo_algoritmo = "Tipo di algoritmo",
    es_algoritmo = "Esempio di output",
    es_brand = "Esempio di piattaforma"
  ) %>%
  autofit()
```

::: {.notes}
+ **Transformers (come GPT)**: predicono il prossimo token in una sequenza, generando testo token per token
+ **GANs**: due reti che "competono" (generator vs discriminator)
+ **VAEs**: codificano dati in spazio latente e poi decodificano
+ **Diffusion models**: partono da rumore e iterativamente lo "denoising" verso l'immagine target
:::


## [INS] FT {.notitle}

![](bib/pagine/png/ft.png){.r-stretch}

<br><br>

::: aside
Dal _Financial Times_: `La storia dei Large Language Models (LLM)`, i.e. Deep Learning applicato al linguaggio naturale  
[https://ig.ft.com/generative-ai/](https://ig.ft.com/generative-ai/)

:::

::: {.notes}
Gli LLM sono Deep Learning applicato al linguaggio.
- Gli LLM usano principalmente Transformer (un tipo particolare di rete neurale) invece dei fully connected layers classici
	- Input: parole/token (frammenti di testo)
	- Strati intermedi: estraggono significati, relazioni grammaticali, concetti
	- Output: previsione della prossima parola o risposta completa

:::


## [INS] Captcha {.notitle}

![](bib/pagine/png/accadeva.png){.r-stretch}

::: {.notes}
xxxxx
:::



## Una panoramica di modelli di IA rilevanti 

- Modelli di linguaggio (LLM): GPT-4, PaLM, LLaMA
- Modelli di visione artificiale: DALL-E, Stable Diffusion, Midjourney
- Modelli multimodali: GPT-4V, CLIP
- Modelli specializzati: Codex (programmazione), BioBERT (biomedicina), ecc.
- Modelli open source vs proprietari
- Piattaforme IA: OpenAI, Google Cloud AI, Azure AI, Hugging Face, ecc.
